{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpEWihCo83eb",
        "colab_type": "text"
      },
      "source": [
        "## We are using **RNN LSTM** to keep the sequence information as we need to keep the information about the complex sentences like I love this movie but not as much that movie. In order to process the complex reviews, we need to maintain the sequence. LSTMs are also known as memory networks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9hsczDo7kHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "be508d34-4bf0-4a80-bd29-6be4d2d37636"
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(1234)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPQCDTui8QF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "070e4795-d8dc-49eb-a0cd-71f5cd93c6cf"
      },
      "source": [
        "#load the dataset but onl keep top 5000 words due to processing problem\n",
        "top_words = 5000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q3NwV87Dqvk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59f4fade-1624-4ddb-ef28-329e822c558f"
      },
      "source": [
        "x_train[4]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 249,\n",
              " 1323,\n",
              " 7,\n",
              " 61,\n",
              " 113,\n",
              " 10,\n",
              " 10,\n",
              " 13,\n",
              " 1637,\n",
              " 14,\n",
              " 20,\n",
              " 56,\n",
              " 33,\n",
              " 2401,\n",
              " 18,\n",
              " 457,\n",
              " 88,\n",
              " 13,\n",
              " 2626,\n",
              " 1400,\n",
              " 45,\n",
              " 3171,\n",
              " 13,\n",
              " 70,\n",
              " 79,\n",
              " 49,\n",
              " 706,\n",
              " 919,\n",
              " 13,\n",
              " 16,\n",
              " 355,\n",
              " 340,\n",
              " 355,\n",
              " 1696,\n",
              " 96,\n",
              " 143,\n",
              " 4,\n",
              " 22,\n",
              " 32,\n",
              " 289,\n",
              " 7,\n",
              " 61,\n",
              " 369,\n",
              " 71,\n",
              " 2359,\n",
              " 5,\n",
              " 13,\n",
              " 16,\n",
              " 131,\n",
              " 2073,\n",
              " 249,\n",
              " 114,\n",
              " 249,\n",
              " 229,\n",
              " 249,\n",
              " 20,\n",
              " 13,\n",
              " 28,\n",
              " 126,\n",
              " 110,\n",
              " 13,\n",
              " 473,\n",
              " 8,\n",
              " 569,\n",
              " 61,\n",
              " 419,\n",
              " 56,\n",
              " 429,\n",
              " 6,\n",
              " 1513,\n",
              " 18,\n",
              " 35,\n",
              " 534,\n",
              " 95,\n",
              " 474,\n",
              " 570,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 138,\n",
              " 88,\n",
              " 12,\n",
              " 421,\n",
              " 1543,\n",
              " 52,\n",
              " 725,\n",
              " 2,\n",
              " 61,\n",
              " 419,\n",
              " 11,\n",
              " 13,\n",
              " 1571,\n",
              " 15,\n",
              " 1543,\n",
              " 20,\n",
              " 11,\n",
              " 4,\n",
              " 2,\n",
              " 5,\n",
              " 296,\n",
              " 12,\n",
              " 3524,\n",
              " 5,\n",
              " 15,\n",
              " 421,\n",
              " 128,\n",
              " 74,\n",
              " 233,\n",
              " 334,\n",
              " 207,\n",
              " 126,\n",
              " 224,\n",
              " 12,\n",
              " 562,\n",
              " 298,\n",
              " 2167,\n",
              " 1272,\n",
              " 7,\n",
              " 2601,\n",
              " 5,\n",
              " 516,\n",
              " 988,\n",
              " 43,\n",
              " 8,\n",
              " 79,\n",
              " 120,\n",
              " 15,\n",
              " 595,\n",
              " 13,\n",
              " 784,\n",
              " 25,\n",
              " 3171,\n",
              " 18,\n",
              " 165,\n",
              " 170,\n",
              " 143,\n",
              " 19,\n",
              " 14,\n",
              " 5,\n",
              " 2,\n",
              " 6,\n",
              " 226,\n",
              " 251,\n",
              " 7,\n",
              " 61,\n",
              " 113]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd6lFmt89i8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b5a48fa-220d-4e4b-a6da-3440a0f14dd8"
      },
      "source": [
        "#max word sequence that comes up is 4999 since we allow only first 5000 wods to load\n",
        "max_number = 0\n",
        "for x in x_train:\n",
        "  for y in x:\n",
        "    if y > max_number:\n",
        "      max_number = y\n",
        "\n",
        "print(max_number)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lejVumOCBVGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# truncate and pad the input sequences\n",
        "#pading is always done in front\n",
        "max_review_length = 500\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_review_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10pklpEiDcE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "71cbe6b9-1918-4e72-a2bb-0feb625b0e92"
      },
      "source": [
        "x_train[4]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    1,  249, 1323,    7,   61,  113,   10,   10,   13, 1637,\n",
              "         14,   20,   56,   33, 2401,   18,  457,   88,   13, 2626, 1400,\n",
              "         45, 3171,   13,   70,   79,   49,  706,  919,   13,   16,  355,\n",
              "        340,  355, 1696,   96,  143,    4,   22,   32,  289,    7,   61,\n",
              "        369,   71, 2359,    5,   13,   16,  131, 2073,  249,  114,  249,\n",
              "        229,  249,   20,   13,   28,  126,  110,   13,  473,    8,  569,\n",
              "         61,  419,   56,  429,    6, 1513,   18,   35,  534,   95,  474,\n",
              "        570,    5,   25,  124,  138,   88,   12,  421, 1543,   52,  725,\n",
              "          2,   61,  419,   11,   13, 1571,   15, 1543,   20,   11,    4,\n",
              "          2,    5,  296,   12, 3524,    5,   15,  421,  128,   74,  233,\n",
              "        334,  207,  126,  224,   12,  562,  298, 2167, 1272,    7, 2601,\n",
              "          5,  516,  988,   43,    8,   79,  120,   15,  595,   13,  784,\n",
              "         25, 3171,   18,  165,  170,  143,   19,   14,    5,    2,    6,\n",
              "        226,  251,    7,   61,  113], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esmml0bQDe-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "badd42d8-63ad-4cd4-bfc0-daf0085d093b"
      },
      "source": [
        "#create the model\n",
        "embedding_vector_length = 50\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=64)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7fbb32441cc0>>\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 380s 15ms/step - loss: 0.4349 - acc: 0.7920 - val_loss: 0.3619 - val_acc: 0.8473\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 378s 15ms/step - loss: 0.2713 - acc: 0.8943 - val_loss: 0.3015 - val_acc: 0.8724\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 373s 15ms/step - loss: 0.2264 - acc: 0.9123 - val_loss: 0.3074 - val_acc: 0.8733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb32450390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9L5OXheKscB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3449450-b0a6-46ce-8d01-e1ecd96c0f7a"
      },
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose= 0)\n",
        "print(scores[1]*100)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4uMzHZhPYDU",
        "colab_type": "text"
      },
      "source": [
        "## Now, the above model was very naive model. Let us add some regularization to the model. For now, I will add **dropout layer** in order to redice the over fitting aspects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErxjEKhOPD4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "b0de8178-b31a-463a-f5d5-21a5d6e77862"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.153))\n",
        "model.add(Dense(1, activation=\"softmax\"))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=64)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 500, 50)           250000    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               60400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 310,501\n",
            "Trainable params: 310,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 326s 13ms/step - loss: 7.9712 - acc: 0.5000\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 328s 13ms/step - loss: 7.9712 - acc: 0.5000\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 332s 13ms/step - loss: 7.9712 - acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb3fb362e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ONUJZJwsH1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a0b0b4b-9d02-471f-923a-cc3a5b8f9410"
      },
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose= 0)\n",
        "print(scores[1]*100)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba04zeS6sFXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "055da5ef-c299-44b6-d51d-fdd089611343"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.153))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=64)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 500, 50)           250000    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 100)               60400     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 310,501\n",
            "Trainable params: 310,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 327s 13ms/step - loss: 0.4648 - acc: 0.7751\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 329s 13ms/step - loss: 0.3626 - acc: 0.8486\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 332s 13ms/step - loss: 0.2721 - acc: 0.8908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb42351a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PaJ5MZbisCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b6995c3-19e3-42a2-a4ef-88e81e66a602"
      },
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose= 0)\n",
        "print(scores[1]*100)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50afmXbJpx2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose= 0)\n",
        "print(scores[1]*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7PYShnygY4p",
        "colab_type": "text"
      },
      "source": [
        "## Keras provides the capability with parameters on the LSTM layer and the dropout layer for configuring the **input dropout and recurrent_dropout** for configuring the recurrent dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFZdeteUe2kR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "0c56fc1c-b829-434f-8391-d3299d2f1fe8"
      },
      "source": [
        "# create model with double dropout i.e. dropout between layers and \n",
        "# dropout within layers of LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length = max_review_length))\n",
        "model.add(LSTM(100, dropout=0.153, recurrent_dropout=0.153))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train, y_train, epochs=3, batch_size=64)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 500, 50)           250000    \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 100)               60400     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 310,501\n",
            "Trainable params: 310,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 362s 14ms/step - loss: 0.4715 - acc: 0.7769\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 360s 14ms/step - loss: 0.3492 - acc: 0.8564\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 364s 15ms/step - loss: 0.3732 - acc: 0.8437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb3dcf4e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao8ISt-girpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97c3c717-1bb4-4dd2-e672-8ef399bad727"
      },
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose= 0)\n",
        "print(scores[1]*100)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.11999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRgfsQV9sKeG",
        "colab_type": "text"
      },
      "source": [
        "## Lets us evaluate the model using **LSTM and CNN**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AIlKTXRsOBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyL_cAQNsjrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fc02c7b-5b31-4a5b-a248-b610635b6d5a"
      },
      "source": [
        "embedding_vector_length = 50\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length = max_review_length))\n",
        "model.add(Conv1D(filters=35, kernel_size=1, padding='same', activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=128)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 50)           250000    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 500, 35)           1785      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 250, 35)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               54400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 306,286\n",
            "Trainable params: 306,286\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "25000/25000 [==============================] - 128s 5ms/step - loss: 0.4783 - acc: 0.7556\n",
            "Epoch 2/5\n",
            "25000/25000 [==============================] - 128s 5ms/step - loss: 0.2500 - acc: 0.9024\n",
            "Epoch 3/5\n",
            "25000/25000 [==============================] - 128s 5ms/step - loss: 0.2118 - acc: 0.9202\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 129s 5ms/step - loss: 0.1887 - acc: 0.9296\n",
            "Epoch 5/5\n",
            "25000/25000 [==============================] - 128s 5ms/step - loss: 0.1712 - acc: 0.9382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb79f04fdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B28MKEO9vg9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66a35b1a-a4d0-4e67-b8d6-d3ac091502b5"
      },
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose= 0)\n",
        "print(scores[1]*100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MagvlaozqCqr",
        "colab_type": "text"
      },
      "source": [
        "#CNN + FLATTEN + DENSE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHoBXhq65ngd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "393ce2a8-5b89-41a6-d85d-5c1442d31c47"
      },
      "source": [
        "from keras.layers import Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length = max_review_length))\n",
        "model.add(Conv1D(filters=35, kernel_size=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "model.fit(x_train, y_train, epochs=6, batch_size=64)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 500, 50)           250000    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 500, 35)           1785      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 17500)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 250)               4375250   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 4,627,286\n",
            "Trainable params: 4,627,286\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.4006 - acc: 0.8020\n",
            "Epoch 2/6\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.1874 - acc: 0.9279\n",
            "Epoch 3/6\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.0819 - acc: 0.9722\n",
            "Epoch 4/6\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.0243 - acc: 0.9934\n",
            "Epoch 5/6\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.0071 - acc: 0.9988\n",
            "Epoch 6/6\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.0016 - acc: 0.9999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb79ac49908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTVY5YgEm8nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "529e3b7a-356d-44ff-8e2b-9ea94e33c08d"
      },
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose= 2)\n",
        "print(scores[1]*100)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85.844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKd---VdqMx8",
        "colab_type": "text"
      },
      "source": [
        "## **Predicting the outputs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKsQH8e9nCBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "02a9a0dd-a347-4834-be15-f9ed5472e355"
      },
      "source": [
        "model.predict_classes(x_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KtY3prGqVpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "767fa83a-d67f-4cbb-8470-031c1a833c15"
      },
      "source": [
        "x_test"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3uQQQxhrXWL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "c07a904a-78a7-49fb-a530-994e1c7de0cb"
      },
      "source": [
        "x_test[0]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    1,  591,  202,   14,   31,    6,  717,   10,\n",
              "         10,    2,    2,    5,    4,  360,    7,    4,  177,    2,  394,\n",
              "        354,    4,  123,    9, 1035, 1035, 1035,   10,   10,   13,   92,\n",
              "        124,   89,  488,    2,  100,   28, 1668,   14,   31,   23,   27,\n",
              "          2,   29,  220,  468,    8,  124,   14,  286,  170,    8,  157,\n",
              "         46,    5,   27,  239,   16,  179,    2,   38,   32,   25,    2,\n",
              "        451,  202,   14,    6,  717], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnu-SWWerRqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}